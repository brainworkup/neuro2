% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/neuro2_llm_integration.R
\name{apply_llm_prompt}
\alias{apply_llm_prompt}
\title{Apply LLM Prompt to Quarto Document}
\usage{
apply_llm_prompt(
  qmd_path,
  prompt_path,
  model = "claude-3-5-sonnet-20241022",
  provider = "anthropic",
  api_key = NULL,
  temperature = 0.3,
  max_tokens = 2000
)
}
\arguments{
\item{qmd_path}{Path to the Quarto document containing the assessment results}

\item{prompt_path}{Path to the JSON file containing the prompt}

\item{model}{Character string specifying the model to use (default: "claude-3-5-sonnet-20241022")}

\item{provider}{Character string specifying the provider ("anthropic", "openai", "ollama")}

\item{api_key}{Optional API key. If NULL, will look for environment variables}

\item{temperature}{Numeric value for response variability (0-1, default: 0.3)}

\item{max_tokens}{Maximum tokens in response (default: 2000)}
}
\value{
Character string containing the LLM-generated interpretation
}
\description{
This function reads a JSON prompt file and a Quarto document, then uses an LLM
to generate interpretations based on the prompt instructions.
}
\examples{
\dontrun{
result <- apply_llm_prompt(
  qmd_path = "_02-01_iq_text.qmd",
  prompt_path = "Prompt General Cognitive Ability.json",
  provider = "anthropic"
)
}
}
