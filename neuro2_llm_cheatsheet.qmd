# neuro2 Enhanced LLM - Cheat Sheet
## Quick Reference Card

---

## üéØ THE ESSENTIALS

### Installation (One-Time Setup)

```bash
# 1. Install Ollama models
ollama pull qwen3:7b      # Essential
ollama pull qwen3:14b-instruct-q4_K_M     # Recommended  
ollama pull qwen3:30b-instruct-q4_K_M     # Optional (best quality)
```

```r
# 2. Install R packages
install.packages(c("future", "future.apply"))
```

### Daily Commands

```r
# Load system
source("R/neuro2_llm.R")

# Generate + render report (RECOMMENDED)
neuro2_run_llm_then_render(
  render_paths = "template.qmd",
  parallel = TRUE,
  n_cores = 6
)

# Check results
view_llm_usage()
```

---

## ‚ö° QUICK COMMANDS

### Testing

```r
neuro2_llm_smoke_test()              # Test connection
check_available_models(...)           # See installed models
```

### Generation

```r
# Fast (parallel)
run_llm_for_all_domains_parallel(n_cores = 6)

# Sequential (original)
run_llm_for_all_domains()

# Single domain
generate_domain_summary_from_master(domain_keyword = "instacad")
```

### Monitoring

```r
view_llm_usage()                     # Summary stats
view_llm_usage(summary_only = FALSE) # Detailed log
```

### Cache Management

```r
llm_cache_dir()                      # Cache location
unlink(llm_cache_dir(), recursive = TRUE)  # Clear cache
```

---

## üéõÔ∏è CONFIGURATION PRESETS

### For Your M3 Max (48GB)

**Daily Reports (Balanced)**
```r
neuro2_run_llm_then_render(
  parallel = TRUE,
  n_cores = 6,
  mega_for_sirf = TRUE,
  validate = TRUE,
  temperature = NULL  # Auto
)
# Time: ~2.5 min | Quality: Excellent (80-90)
```

**Speed Priority**
```r
neuro2_run_llm_then_render(
  parallel = TRUE,
  n_cores = 8,
  mega_for_sirf = FALSE,  # Use 14B
  validate = FALSE,
  model_override = "llama3.2:3b-instruct-q4_K_M"
)
# Time: ~2 min | Quality: Good (75-85)
```

**Quality Priority**
```r
neuro2_run_llm_then_render(
  parallel = TRUE,
  n_cores = 4,
  mega_for_sirf = TRUE,   # Use 32B
  validate = TRUE,
  temperature = 0.25
)
# Time: ~4 min | Quality: Superior (85-95)
```

---

## üîç VALIDATION REFERENCE

### Quality Score Interpretation

| Score | Grade | Action |
|-------|-------|--------|
| 90-100 | Excellent | Use as-is ‚úÖ |
| 80-89 | Very Good | Minor review üëç |
| 70-79 | Good | Quick check ‚úì |
| 60-69 | Fair | Review recommended ‚ö†Ô∏è |
| <60 | Poor | Regenerate with larger model ‚ùå |

### Check Quality

```r
validation <- validate_clinical_output(text)
validation$quality_score  # 0-100
validation$issues         # Critical problems
validation$warnings       # Minor issues
```

---

## üé® MODEL SELECTION GUIDE

### Recommended Models by Use Case

**Domain Summaries (8B)**
- Primary: `qwen2.5:7b-instruct-q4_K_M` ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Fast: `llama3.2:3b-instruct-q4_K_M` ‚ö°‚ö°‚ö°‚ö°‚ö°
- Clinical: `gemma2:9b-instruct-q4_K_M` üè•üè•üè•üè•

**SIRF Analysis (14B)**
- Primary: `qwen2.5:14b-instruct-q4_K_M` ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Balanced: `llama3.1:8b-instruct-q4_K_M` üî•üî•üî•üî•

**Mega/Comprehensive (30B+)**
- Best: `qwen2.5:32b-instruct-q4_K_M` ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Alternative: `command-r:35b-v0.1-q4_K_M` üè•üè•üè•üè•

### Check What You Have

```r
# See all installed
system("ollama list")

# Check specific models
check_available_models(
  c("qwen2.5:7b-instruct-q4_K_M", "llama3.2:3b-instruct-q4_K_M"),
  "ollama"
)
```

---

## üêõ TROUBLESHOOTING FLOWCHART

```
Problem?
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Run: neuro2_llm_smoke_test() ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
  ‚îú‚îÄ ‚úÖ OK ‚Üí System working
  ‚îÇ
  ‚îî‚îÄ ‚ùå Error
      ‚Üì
      ‚îú‚îÄ "No models" ‚Üí ollama pull qwen2.5:7b-instruct-q4_K_M
      ‚îÇ
      ‚îú‚îÄ "Package missing" ‚Üí install.packages(c("future", "future.apply"))
      ‚îÇ
      ‚îî‚îÄ Other error ‚Üí view_llm_usage(summary_only = FALSE)
```

### Quick Fixes

```r
# Problem: Generation fails
Solution: check_available_models(...) then install missing models

# Problem: Slow generation
Solution: n_cores = 2, validate = FALSE

# Problem: Low quality
Solution: model_override = "qwen2.5:14b-instruct-q4_K_M"

# Problem: Parallel not working
Solution: install.packages(c("future", "future.apply"))
```

---

## üìä PERFORMANCE REFERENCE

### Expected Timing (M3 Max, 20 domains)

| Config | Time | Quality | Memory |
|--------|------|---------|--------|
| **Sequential** | 10 min | 75-85 | 4 GB |
| **Parallel (2 cores)** | 5 min | 75-85 | 6 GB |
| **Parallel (6 cores)** | 2.5 min | 80-90 | 10 GB |
| **Parallel + Mega** | 4 min | 85-95 | 15 GB |

### Model Speed Comparison

| Model | Size | Speed | Quality |
|-------|------|-------|---------|
| llama3.2:3b | 3B | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| qwen2.5:7b | 7B | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| qwen2.5:14b | 14B | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| qwen2.5:32b | 32B | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

## üéì COMMON PATTERNS

### Pattern 1: Standard Daily Report

```r
source("R/neuro2_llm.R")
neuro2_run_llm_then_render(
  render_paths = "patient_report.qmd",
  parallel = TRUE,
  n_cores = 6
)
```

### Pattern 2: Batch Processing

```r
for (patient in c("A", "B", "C")) {
  neuro2_run_llm_then_render(
    base_dir = patient,
    render_paths = file.path(patient, "report.qmd"),
    parallel = TRUE,
    n_cores = 6
  )
}
```

### Pattern 3: Two-Pass Quality Assurance

```r
# Pass 1: Fast draft
results <- run_llm_for_all_domains_parallel(n_cores = 8)

# Pass 2: Regenerate low-quality domains
problem_domains <- identify_low_quality(results)
regenerate_with_larger_model(problem_domains)
```

### Pattern 4: Single Domain Testing

```r
result <- generate_domain_summary_from_master(
  domain_keyword = "instacad",
  validate = TRUE,
  max_retries = 3
)
```

---

## üìà USAGE MONITORING

### Key Metrics

```r
view_llm_usage()

# Watch for:
# - Success rate (should be >95%)
# - Average time (should be 10-20s per domain)
# - Total tokens (track trends)
# - Models used (confirm using right ones)
```

### Optimization Signals

**Too Slow?**
- Increase `n_cores`
- Use smaller models
- Disable validation temporarily

**Low Quality?**
- Use larger models
- Decrease `temperature`
- Enable strict validation

**Frequent Failures?**
- Check `view_llm_usage(summary_only = FALSE)`
- Verify models installed: `ollama list`
- Test connection: `neuro2_llm_smoke_test()`

---

## üîë KEY SETTINGS EXPLAINED

### n_cores
- **2:** Safe, conservative
- **4:** Good balance
- **6:** Recommended for M3 Max (Daily use)
- **8:** Maximum speed (Occasional use)

### mega_for_sirf
- **FALSE:** Use 14B model (faster, good quality)
- **TRUE:** Use 32B model (slower, best quality)

### validate
- **TRUE:** Check quality automatically (recommended)
- **FALSE:** Skip validation (use for speed)

### temperature
- **0.2:** More deterministic (domain summaries)
- **0.35:** More creative (SIRF analysis)
- **NULL:** Auto (recommended)

### max_retries
- **1:** Fast but less reliable
- **2:** Good balance (default)
- **3:** Maximum reliability

---

## üíæ FILE LOCATIONS

```
Cache: llm_cache_dir()
  ‚îî‚îÄ /tmp/Rtmp.../neuro2_llm_cache/

Log: llm_usage_log()
  ‚îî‚îÄ /tmp/Rtmp.../neuro2_llm_cache/usage_log.csv

Code: R/neuro2_llm.R
  ‚îî‚îÄ Your project directory
```

---

## üéØ SUCCESS CHECKLIST

Before each report:
- [ ] Models installed (`ollama list`)
- [ ] Smoke test passes (`neuro2_llm_smoke_test()`)
- [ ] Cache cleared if needed (`unlink(llm_cache_dir(), recursive = TRUE)`)

After each report:
- [ ] Quality scores ‚â•70
- [ ] No failed generations
- [ ] Review usage stats (`view_llm_usage()`)
- [ ] Generated text reads well

---

## üìû EMERGENCY CONTACTS

**Documentation:**
- Quick Start: `neuro2_llm_quickstart.md`
- Full Guide: `neuro2_llm_user_guide.md`
- Comparison: `neuro2_llm_comparison.md`

**Commands:**
```r
# Test everything
neuro2_llm_smoke_test()

# Check installation
check_available_models(get_model_config("domain", "primary"), "ollama")

# View logs
view_llm_usage(summary_only = FALSE)

# Clear cache
unlink(llm_cache_dir(), recursive = TRUE)
```

**Fallback:**
```r
# Use sequential if parallel fails
run_llm_for_all_domains(validate = FALSE)
```

---

## üéâ FINAL REMINDERS

1. **Start with defaults** - They're optimized for your M3 Max
2. **Monitor quality scores** - Should consistently be ‚â•70
3. **Use parallel processing** - It's 4x faster
4. **Enable validation** - Catches issues automatically
5. **Check logs regularly** - `view_llm_usage()`

---

## üì± QUICK COPY-PASTE

```r
# === DAILY WORKFLOW ===

# 1. Load
source("R/neuro2_llm.R")

# 2. Test (optional)
neuro2_llm_smoke_test()

# 3. Generate
neuro2_run_llm_then_render(
  render_paths = "report.qmd",
  parallel = TRUE,
  n_cores = 6,
  mega_for_sirf = TRUE,
  validate = TRUE
)

# 4. Check
view_llm_usage()
```

---

**Print this page and keep it handy!**

---

**Version:** 2.0  
**Optimized for:** M3 Max 48GB  
**Last Updated:** 2025-01-18
