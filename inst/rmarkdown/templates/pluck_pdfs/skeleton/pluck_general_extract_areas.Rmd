---
title: |
  <center> Neurocognitive Data </center>
  <center> Any Test </center>
date: "`r Sys.Date()`"
params:
  patient: Biggie
  test:
    label: "Test"
    value: "wrat5"
    input: select
    multiple: no
    choices:
      - wais4
      - wais5
      - wisc5
      - wms4
      - wrat5
      - nab
      - brown_efa_self
      - brown_efa_parent
      - brown_efa_teacher
  test_name:
    label: "Test Name"
    value: "WRAT-5"
    input: select
    multiple: no
    choices:
      - WAIS-IV
      - WAIS-5
      - WISC-V
      - WMS-IV
      - WRAT-5
      - NAB
      - Brown EF/A Self-Report
      - Brown EF/A Parent Ratings
      - Brown EF/A Teacher Ratings
  file:
    label: "No file selected"
    value: file
    input: file
  pages: [2,3,6]
  extract_columns: [2,4,5,6]
  variables:
    label: "Variable Names"
    value: [scale, raw_score, score, ci_95, percentile]
    input: select
    multiple: yes
    choices:
      - scale
      - raw_score
      - score
      - ci_95
      - percentile
      - category
      - domain
      - abbrev
      - base_rate
      - z_score
      - sem
      - ref_group_ss
      - grade_equiv
      - age_equiv
      - nce
      - gsv
  extract_columns_label:
    label: "Columns to keep"
    value: [scale, raw_score, score, ci_95, percentile]
    input: select
    multiple: yes
    choices:
      - scale
      - raw_score
      - score
      - ci_95
      - percentile
      - category
      - description
      - base_rate
  score_type:
    label: "Score type"
    value: standard_score
    input: radio
    choices:
      - standard_score
      - t_score
      - scaled_score
      - z_score
      - raw_score
      - base_rate
  test_type:
    label: "Test Type"
    value: "npsych_test"
    input: radio
    choices:
      - npsych_test
      - rating_scale
      - performance_validity
      - symptom_validity
  compute_percentile: FALSE
  compute_ci95: FALSE
  # do subtests need to be merged?
  subtests: FALSE
output:
  rmdformats::robobook:
    highlight: kate
---

## Load libraries

```{r setup, include = FALSE}
Sys.setenv(
  JAVA_HOME =
    "/Library/Java/JavaVirtualMachines/graalvm-jdk-22.0.1+8.1/Contents/Home"
)
options(java.parameters = "-Xmx16000m")
knitr::opts_chunk$set(
  root.dir = normalizePath("./"),
  echo = TRUE,
  message = TRUE,
  warning = FALSE,
  error = TRUE
)
library(collapse)
library(dplyr)
library(glue)
library(hablar)
library(here)
library(knitr)
library(magrittr)
library(purrr)
library(qs)
library(readr)
library(rJava)
library(rlang)
library(rmarkdown)
library(rmdformats)
library(shiny)
library(snakecase)
library(tabulapdf)
library(tibble)
library(tidyr)
library(vroom)
library(NeurotypR)
library(bwu)
```

## Parameters

NOTE: moved to `params.R` file ...
can use those

```{r eval = FALSE}
# source("params.R")
patient <- params$patient
test <- params$test
test_name <- params$test_name
# file <- file.path(file.choose())
file <- file.path(params$file)
pages <- (params$pages)
score_type <- params$score_type
extract_columns <- params$extract_columns
variables <- params$variables

qs2::qd_save(file, paste0(test, "_path.rds"))
# file <- qs::qread(paste0(test, "_path.rds"))

# saveRDS(file, paste0("file_pdf", test, ".rds")) # eventually update to data directory
# f <- readRDS(paste0("file_pdf", test, ".rds"))
```

## Extract areas with `tabulapdf`

NOTE: Do this in R first in `params.R` file, not here

```{r eval = FALSE}
# file <- file.path("data", "pdf", paste0(test, ".pdf"))
# file <- file.path(file.choose(""))

params <-
  list(
    patient = patient,
    test = test,
    test_name = test_name,
    file = file,
    pages = pages,
    extract_columns = extract_columns,
    score_type = score_type
  )

extracted_areas <- tabulapdf::extract_areas(
  file = file,
  pages = pages,
  method = "decide",
  output = "matrix",
  copy = TRUE
)
```

```{r eval=FALSE}
# Loop over the list and write each matrix to a CSV file
for (i in seq_along(extracted_areas)) {
  write.csv(extracted_areas[[i]], file = paste0(test, "_", i, ".csv"), row.names = FALSE)
}

# Save the entire list to an R data file
# save(extracted_areas, file = paste0(test, "_extracted_areas.RData"))
saveRDS(extracted_areas, paste0(test, "_extracted_areas.rds"))

# Check the extracted areas
str(extracted_areas)

# To read the extracted areas back in
# extracted_areas <- readRDS(paste0(test, "_extracted_areas.rds"))

# To merge the extracted areas into a single data frame
df <- data.frame(extracted_areas)
```

# Functions

## Function to merge subtests

```{r eval = params$subtests}
# Function to merge subtests
merge_subtests <- function(test, suffix = "csv") {
  # Get the list of files matching the prefix and suffix
  files <- dir(pattern = paste0(test, "_[0-9]+\\.", suffix))

  # If no files are found, return an empty data frame
  if (length(files) == 0) {
    return(data.frame())
  }

  # Read in the first file
  df <- readr::read_csv(files[1])

  # Read in and bind the remaining files
  for (file in files[-1]) {
    temp_df <- readr::read_csv(file)
    df <- dplyr::bind_rows(df, temp_df)
  }

  # Return the merged data frame
  return(df)
}

df <- merge_subtests(test)
```

## Function to extract columns by position

```{r}
library(dplyr)

extract_columns <- extract_columns

# Function to extract columns by position
extract_columns_by_position <- function(df, positions) {
  df[, positions]
}

# To save the filtered data.frame separately
# filtered_df <- extract_columns_by_position(df, params$extract_columns)
filtered_df <- extract_columns_by_position(df, extract_columns)

# To overwrite the original data.frame
# df <- extract_columns_by_position(df, params$extract_columns)
df <- extract_columns_by_position(df, extract_columns)

# Rename the variables
# colnames(df) <- params$variables
colnames(df) <- variables

# Step 1: Replace "-" with NA in the entire dataframe
df[df == "-"] <- NA

# Step 2 (Optional): Convert 'raw score' 'score' and 'percentile' to numeric
df <- df |>
  mutate(
    raw_score = as.numeric(raw_score),
    score = as.numeric(score),
    percentile = as.numeric(percentile)
  )

# Step 3: Remove rows where 'score' or 'percentile' are missing
df <- df |>
  filter(!is.na(score) & !is.na(percentile))
```

### Function to calculate 95% CI if needed

```{r eval = params$compute_ci95}
# Assuming df is your data.frame and calc_ci_95 is your function
for (i in seq_len(nrow(df))) {
  ci_values <- bwu::calc_ci_95(
    ability_score = df$score[i],
    mean = 10, # change to 50, 0, 100, etc.
    standard_deviation = 3, # change to 10, 1, 15, etc.
    reliability = .90
  )
  df$true_score[i] <- ci_values["true_score"]
  df$ci_lo[i] <- ci_values["lower_ci_95"]
  df$ci_hi[i] <- ci_values["upper_ci_95"]
  df$ci_95[i] <- paste0(ci_values["lower_ci_95"], " - ", ci_values["upper_ci_95"])
}

df <- df |>
  dplyr::select(-c(true_score, ci_lo, ci_hi)) |>
  dplyr::relocate(ci_95, .after = score)
```

# Lookup Table Match

```{r eval = TRUE}
# Load the lookup table
lookup_table <- readr::read_csv("~/reports/neuropsych_lookup_table_combined.csv")

# Merge the data with the lookup table
df_merged <- dplyr::mutate(df, test = test) |>
  dplyr::left_join(lookup_table, by = c("test" = "test", "scale" = "scale")) |>
  dplyr::relocate(c(test, test_name), .before = scale)

# add missing columns
df_mutated <- bwu::gpluck_make_columns(
  df_merged,
  range = "",
  result = "",
  absort = NULL
)

rm(df_merged)
```

## Test score ranges

```{r ranges, eval = TRUE}
df_mutated <- df_mutated |>
  dplyr::mutate(range = NULL) |>
  bwu::gpluck_make_score_ranges(table = df_mutated, test_type = "npsych_test") |>
  dplyr::relocate(c(range), .after = percentile)
```

## Glue results for each scale

```{r results, eval = TRUE}
df <- df_mutated |>
  dplyr::mutate(
    result = ifelse(
      percentile == 1,
      glue::glue("{description} fell within the {range} and ranked at the {percentile}st percentile, indicating performance as good as or better than {percentile}% of same-age peers from the general population.\n"),
      ifelse(
        percentile == 2,
        glue::glue("{description} fell within the {range} and ranked at the {percentile}nd percentile, indicating performance as good as or better than {percentile}% of same-age peers from the general population.\n"),
        ifelse(
          percentile == 3,
          glue::glue("{description} fell within the {range} and ranked at the {percentile}rd percentile, indicating performance as good as or better than {percentile}% of same-age peers from the general population.\n"),
          glue::glue("{description} fell within the {range} and ranked at the {percentile}th percentile, indicating performance as good as or better than {percentile}% of same-age peers from the general population.\n")
        )
      )
    )
  ) |>
  dplyr::select(-description) |>
  dplyr::relocate(absort, .after = result)
```

## Write out final csv

```{r write}
test <- "wisc5_1"
readr::write_excel_csv(df, here::here("data", "csv", paste0(test, ".csv")), col_names = TRUE)
```

## Write to "g2.csv" file

```{r g2, eval = TRUE}
has_headers <- function(file_path) {
  if (!file.exists(file_path)) {
    return(FALSE) # File doesn't exist, headers are needed
  }
  # Check if the file has at least one line (header)
  return(length(readLines(file_path, n = 1)) > 0)
}

csv_file <- df
g <- "g2"
file_path <- here::here("data", paste0(g, ".csv"))

readr::write_excel_csv(
  csv_file,
  file_path,
  append = TRUE,
  col_names = !has_headers(file_path),
  quote = "all"
)
```

**THE END!!**
